{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566a98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc6f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複勝の1行化\n",
    "\n",
    "#!pip install optuna\n",
    "fukusho = pd.read_csv('./fukusho20220909.csv')\n",
    "groups = fukusho.groupby('レースID(新/馬番無)').groups\n",
    "\n",
    "column_list = ['複勝配当', \"馬番\"]\n",
    "new_df = pd.DataFrame()\n",
    "max_length = 0\n",
    "for group, indexes in groups.items():\n",
    "    # 最後に並び替えをさせるのに最大作成された項目数を記録\n",
    "    length = len(indexes)+1\n",
    "    if length > max_length:\n",
    "        max_length = length\n",
    "\n",
    "    columns = list()\n",
    "    values = list()\n",
    "    columns += ['レースID(新/馬番無)']\n",
    "    values += [fukusho.iloc[indexes]['レースID(新/馬番無)'].T.tolist()[0]]\n",
    "#     values = values.sort_values(by='pred_time', ascending = True)\n",
    "    # race_id = [target_column['race_id']]\n",
    "    # columns += ['レースID(新/馬番無)']\n",
    "    # values += [race_detail.iloc[indexes]['レースID(新/馬番無)'].T.tolist()[0]]\n",
    "\n",
    "    for target_column in column_list:\n",
    "        columns += [f'{target_column}_{x}' for x in range(1, length)]\n",
    "        sort_values = fukusho.iloc[indexes, :]\n",
    "        values += sort_values[target_column].T.tolist()\n",
    "    \n",
    "#     values.sort(reverse=True)\n",
    "    record_df = pd.DataFrame([values], columns=columns)\n",
    "    new_df = pd.concat([new_df, record_df], axis=0)\n",
    "new_df.to_csv('./fukusho20220909_fukusho.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a10df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 血統情報取得\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def scrape_peds(horse_id_list, pre_peds={}):\n",
    "    peds = pre_peds\n",
    "    for horse_id in tqdm(horse_id_list):\n",
    "        if horse_id in peds.keys():\n",
    "            continue\n",
    "        try:\n",
    "            url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "            df = pd.read_html(url)[0]\n",
    "            \n",
    "            generations = {}\n",
    "            for i in reversed(range(5)):\n",
    "                generations[i] = df[i]\n",
    "                df.drop([i], axis=1, inplace=True)\n",
    "                df = df.drop_duplicates()\n",
    "            \n",
    "            ped = pd.concat([generations[i] for i in range(5)]).rename(horse_id)\n",
    "            peds[horse_id] = ped.reset_index(drop=True)\n",
    "            time.sleep(1)\n",
    "        except IndexError:\n",
    "            continue\n",
    "        except:\n",
    "            break\n",
    "    return peds\n",
    "\n",
    "def horse_data(horse_id_list, pre_peds={}):\n",
    "    peds = pre_peds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87e738d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 49/49 [01:13<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "horses = pd.read_csv('./horseid.csv')\n",
    "targets = horses['horse_id'].astype(str)\n",
    "peds = scrape_peds(targets)\n",
    "peds = pd.concat([peds[horse_id] for horse_id in peds], axis=1).T\n",
    "peds = peds.add_prefix('peds_')\n",
    "peds.to_pickle('peds4.pickle')\n",
    "p = pd.read_pickle('peds4.pickle')\n",
    "p.to_csv('peds_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83969172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "peds = pd.read_csv('./csv_new2/horses.csv')\n",
    "\n",
    "ft_model = fasttext.load_model('ketto_model.bin')\n",
    "def vec(x):\n",
    "    try:\n",
    "        sum = ft_model.get_sentence_vector(x).sum()\n",
    "        if sum == 0:\n",
    "            return None\n",
    "        return sum\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "for i in range(1, 63):\n",
    "    peds['peds_' + str(i)] = peds['peds' + str(i)].map(lambda x: vec(x))\n",
    "    peds.drop(['peds' + str(i)], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a208a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('./csv_new2/horse_names.csv')\n",
    "\n",
    "vec = names.merge(peds, on=['name']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88e5e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target_columns = [\n",
    "    \"peds_1\", \"peds_2\",\"peds_3\",\"peds_4\",\"peds_5\",\"peds_6\",\"peds_7\",\"peds_8\",\"peds_9\",\"peds_10\",\n",
    "    \"peds_11\",\"peds_12\",\"peds_13\",\"peds_14\",\n",
    "    \"peds_15\",\"peds_16\",\"peds_17\",\"peds_18\",\"peds_19\",\"peds_20\",\n",
    "    \"peds_21\",\"peds_22\",\n",
    "    \"peds_23\",\"peds_24\",\"peds_25\",\"peds_26\",\"peds_27\",\"peds_28\",\"peds_29\",\"peds_30\",\n",
    "    \"peds_31\",\"peds_32\",\"peds_33\",\"peds_34\",\"peds_35\",\"peds_36\",\"peds_37\",\"peds_38\",\"peds_39\",\"peds_40\",\n",
    "    \"peds_41\",\"peds_42\",\"peds_43\",\"peds_44\",\"peds_45\",\"peds_46\",\"peds_47\",\"peds_48\",\"peds_49\",\"peds_50\",\n",
    "    \"peds_51\",\"peds_52\",\"peds_53\",\"peds_54\",\"peds_55\",\"peds_56\",\"peds_57\",\"peds_58\",\"peds_59\",\n",
    "    \"peds_60\",\"peds_61\",\"peds_62\"\n",
    "]\n",
    "\n",
    "df = vec.drop([\"name\"], axis=1)\n",
    "for column in target_columns:\n",
    "    df[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "\n",
    "for column in target_columns:\n",
    "    df[column] = df[column].astype('category')\n",
    "\n",
    "df.to_pickle('./pickle_new/peds_vec.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2afbb855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = pd.read_csv('./csv_new2/base/race_detail_2.csv')\n",
    "\n",
    "horse_sire_rate = pd.read_csv('./csv_new2/base/horse_sire_rate.csv')\n",
    "horse_sire_rate.drop(['race_id', 'name', 'course', 'distance', 'date', 'place_id', 'start_time'], axis=1, inplace=True)\n",
    "base['horse_race_id'] = base['id']\n",
    "\n",
    "circle_rate = pd.read_csv('./csv_new2/base/circle_rate.csv')\n",
    "new_race_trainings = base.merge(circle_rate, on='horse_race_id')\n",
    "\n",
    "jockey_rate = pd.read_csv('./csv_new2/base/jockey_rate.csv')\n",
    "jockey_rate.drop(['id', 'jockey_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "trainer_rate = pd.read_csv('./csv_new2/base/trainer_rate.csv')\n",
    "trainer_rate.drop(['id', 'trainer_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "stallion_rate = pd.read_csv('./csv_new2/base/stallion_rate.csv')\n",
    "stallion_rate.drop(['place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "\n",
    "new_race_trainings_horses = new_race_trainings.merge(jockey_rate, how='left', on='horse_race_id')\n",
    "new_race_trainings_horses = new_race_trainings_horses.merge(trainer_rate, how='left', on='horse_race_id')\n",
    "new_race_trainings_horses = new_race_trainings_horses.merge(stallion_rate, how='left', on=['race_id', 'stallion_id'])\n",
    "\n",
    "weather = pd.read_csv('./csv_new2/weathers.csv')\n",
    "base_conc = new_race_trainings_horses.merge(weather, on='race_id')\n",
    "base_conc['date'] = base_conc['date_y']\n",
    "base_conc = base_conc.merge(horse_sire_rate, how='left', on='id')\n",
    "\n",
    "seasons = pd.read_csv('./csv_new2/season_rate.csv')\n",
    "b = base_conc.merge(seasons, how='left', on='id')\n",
    "\n",
    "b.drop(['name', 'date_y', 'date_x', 'start_time'], axis=1, inplace=True)\n",
    "\n",
    "horse_results_detail = pd.read_csv('./csv_new2/base/horse_results_detail.csv')\n",
    "horse_results_detail = horse_results_detail.drop(['horse_id', 'age', 'course', 'distance', 'career', 'date', 'race_id'], axis=1)\n",
    "b = b.merge(horse_results_detail, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6080c5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_74852/3654046672.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n"
     ]
    }
   ],
   "source": [
    "standard_scaler = lambda  x: (x - x.mean()) / x.std()\n",
    "\n",
    "targets = [\n",
    "    '騎手全体勝率','騎手全体連対率','騎手全体複勝率','騎手競馬場別騎乗回数','騎手競馬場別勝率','騎手競馬場別連対率','騎手競馬場別複勝率',\n",
    "    '騎手コース別騎乗回数','騎手コース別勝率','騎手コース別連対率','騎手コース別複勝率','騎手距離別騎乗回数','騎手距離別勝率','騎手距離別連対率',\n",
    "    '騎手距離別複勝率','騎手同コース同距離別騎乗回数','騎手同コース同距離別勝率','騎手同コース同距離別連対率','騎手同コース同距離別複勝率',\n",
    "    '調教師全体勝率','調教師全体連対率','調教師全体複勝率','調教師競馬場別騎乗回数','調教師競馬場別勝率','調教師競馬場別連対率',\n",
    "    '調教師競馬場別複勝率','調教師コース別騎乗回数','調教師コース別勝率','調教師コース別連対率','調教師コース別複勝率','調教師距離別騎乗回数',\n",
    "    '調教師距離別勝率','調教師距離別連対率','調教師距離別複勝率','調教師同コース同距離別騎乗回数','調教師同コース同距離別勝率',\n",
    "    '調教師年齢別年間勝率', '調教師年齢別年間連対率', '調教師年齢別年間複勝率','調教師年齢別勝率', '調教師年齢別連対率', '調教師年齢別複勝率',\n",
    "    '調教師同コース同距離別連対率','調教師同コース同距離別複勝率','種牡馬全体勝率','種牡馬全体連対率','種牡馬全体複勝率',\n",
    "    '種牡馬競馬場別出走頭数','種牡馬競馬場別勝率','種牡馬競馬場別連対率','種牡馬競馬場別複勝率','種牡馬コース別出走頭数','種牡馬コース別勝率',\n",
    "    '種牡馬コース別連対率','種牡馬コース別複勝率','種牡馬距離別出走頭数','種牡馬距離別勝率','種牡馬距離別連対率','種牡馬距離別複勝率',\n",
    "    '種牡馬同コース同距離別出走頭数','種牡馬同コース同距離別勝率','種牡馬同コース同距離別連対率','種牡馬同コース同距離別複勝率',\n",
    "    '種牡馬同周り勝率', '種牡馬同周り連対率', '種牡馬同周り複勝率',  '種牡馬同枠勝率', '種牡馬同枠連対率', '種牡馬同枠複勝率',\n",
    "    '父系統出走頭数','父系統全体勝率','父系統全体連対率','父系統全体複勝率','父系統競馬場別出走頭数','父系統競馬場別勝率','父系統競馬場別連対率','父系統競馬場別複勝率','父系統コース別出走頭数','父系統コース別勝率',\n",
    "    '父系統コース別連対率','父系統コース別複勝率','父系統距離別出走頭数','父系統距離別勝率','父系統距離別連対率','父系統距離別複勝率',\n",
    "    '父系統同コース同距離別出走頭数','父系統同コース同距離別勝率','父系統同コース同距離別連対率','父系統同コース同距離別複勝率',\n",
    "    '季節勝率', '季節連対率', '季節複勝率', '逃げ率','先行率','中団率','追込率','マクリ率','上がり3F平均',\n",
    "    '勝率','同競馬場勝率','同距離勝率','同競馬場同距離勝率','同騎手騎乗勝率','コースタイプ勝率','同距離同クラス勝率','同枠タイプ生涯勝率',\n",
    "    '連対率','同競馬場連対率','同距離連対率','同競馬場同距離連対率','同騎手騎乗連対率','コースタイプ連対率','同距離同クラス連対率','同枠タイプ生涯連対率',\n",
    "    '複勝率','同競馬場複勝率','同距離複勝率','同競馬場同距離複勝率','同騎手騎乗複勝率','コースタイプ複勝率','同距離同クラス複勝率','同枠タイプ生涯複勝率',\n",
    "    '生涯出遅れ率','騎乗騎手年間出遅れ率', '同周り勝率', '同周り連対率', '同周り複勝率'\n",
    "]\n",
    "\n",
    "# b = b.set_index('race_id')\n",
    "for t in targets:\n",
    "    b[t + '偏差'] = b.groupby('race_id')[t].transform(standard_scaler)\n",
    "    \n",
    "# b.drop(targets, axis=1, inplace=True)\n",
    "\n",
    "cp_all_rb = b.copy()\n",
    "ind = ['先行指数', 'ペース指数', '上がり指数', 'スピード指数']\n",
    "for i in range(1, 6):\n",
    "    for idx in ind:\n",
    "        cp_all_rb[str(i) + '走前'+ idx + '偏差'] = cp_all_rb.groupby(level=0)[str(i) + '走前'+ idx].transform(standard_scaler)\n",
    "        \n",
    "b_conc = cp_all_rb.reset_index()\n",
    "b_copy = b_conc.copy()\n",
    "\n",
    "b_copy.to_pickle('./pickle_new/base_race_20221016.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7fba462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_38971/4152359629.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    }
   ],
   "source": [
    "# 新馬戦\n",
    "standard_scaler = lambda  x: (x - x.mean()) / x.std()  * 10 + 50\n",
    "\n",
    "base = pd.read_csv('./csv_new2/base/race_detail_shinba.csv')\n",
    "horse_sire_rate = pd.read_csv('./csv_new2/base/horse_sire_rate.csv')\n",
    "\n",
    "horse_sire_rate.drop(['race_id', 'name', 'course', 'distance', 'date', 'place_id', 'start_time'], axis=1, inplace=True)\n",
    "\n",
    "base['horse_race_id'] = base['id']\n",
    "\n",
    "jockey_rate = pd.read_csv('./csv_new2/base/jockey_rate.csv')\n",
    "jockey_rate.drop(['id', 'jockey_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "trainer_rate = pd.read_csv('./csv_new2/base/trainer_rate.csv')\n",
    "trainer_rate.drop(['id', 'trainer_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "stallion_rate = pd.read_csv('./csv_new2/base/stallion_rate.csv')\n",
    "stallion_rate.drop(['place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "\n",
    "new_race_trainings_horses = base.merge(jockey_rate, how='left', on='horse_race_id')\n",
    "new_race_trainings_horses = new_race_trainings_horses.merge(trainer_rate, how='left', on='horse_race_id')\n",
    "new_race_trainings_horses = new_race_trainings_horses.merge(stallion_rate, how='left', on=['race_id', 'stallion_id'])\n",
    "\n",
    "new_race_trainings_horses.drop(['result_except'], axis=1, inplace=True)\n",
    "\n",
    "weather = pd.read_csv('./csv_new2/weathers.csv')\n",
    "base_conc = new_race_trainings_horses.merge(weather, on='race_id')\n",
    "base_conc['date'] = base_conc['date_y']\n",
    "base_conc.drop(['date_y', 'date_x', 'start_time'], axis=1, inplace=True)\n",
    "base_conc = base_conc.merge(horse_sire_rate, how='left', on='id')\n",
    "\n",
    "seasons = pd.read_csv('./csv_new2/season_rate.csv')\n",
    "b = base_conc.merge(seasons, how='left', on='id')\n",
    "\n",
    "b.drop(['name', 'sireline'], axis=1, inplace=True)\n",
    "\n",
    "horse_results_detail = pd.read_csv('./csv_new2/base/horse_results_detail.csv')\n",
    "horse_results_detail = horse_results_detail.drop(['horse_id', 'age', 'course', 'distance', 'career', 'date', 'race_id'], axis=1)\n",
    "b = b.merge(horse_results_detail, how='left', on='id')\n",
    "\n",
    "standard_scaler = lambda  x: (x - x.mean()) / x.std()\n",
    "\n",
    "targets = [\n",
    "    '騎手全体勝率','騎手全体連対率','騎手全体複勝率','騎手競馬場別騎乗回数','騎手競馬場別勝率','騎手競馬場別連対率','騎手競馬場別複勝率',\n",
    "    '騎手コース別騎乗回数','騎手コース別勝率','騎手コース別連対率','騎手コース別複勝率','騎手距離別騎乗回数','騎手距離別勝率','騎手距離別連対率',\n",
    "    '騎手距離別複勝率','騎手同コース同距離別騎乗回数','騎手同コース同距離別勝率','騎手同コース同距離別連対率','騎手同コース同距離別複勝率',\n",
    "    '調教師全体勝率','調教師全体連対率','調教師全体複勝率','調教師競馬場別騎乗回数','調教師競馬場別勝率','調教師競馬場別連対率',\n",
    "    '調教師競馬場別複勝率','調教師コース別騎乗回数','調教師コース別勝率','調教師コース別連対率','調教師コース別複勝率','調教師距離別騎乗回数',\n",
    "    '調教師距離別勝率','調教師距離別連対率','調教師距離別複勝率','調教師同コース同距離別騎乗回数','調教師同コース同距離別勝率',\n",
    "    '調教師年齢別年間勝率', '調教師年齢別年間連対率', '調教師年齢別年間複勝率','調教師年齢別勝率', '調教師年齢別連対率', '調教師年齢別複勝率',\n",
    "    '調教師同コース同距離別連対率','調教師同コース同距離別複勝率','種牡馬全体勝率','種牡馬全体連対率','種牡馬全体複勝率',\n",
    "    '種牡馬競馬場別出走頭数','種牡馬競馬場別勝率','種牡馬競馬場別連対率','種牡馬競馬場別複勝率','種牡馬コース別出走頭数','種牡馬コース別勝率',\n",
    "    '種牡馬コース別連対率','種牡馬コース別複勝率','種牡馬距離別出走頭数','種牡馬距離別勝率','種牡馬距離別連対率','種牡馬距離別複勝率',\n",
    "    '種牡馬同コース同距離別出走頭数','種牡馬同コース同距離別勝率','種牡馬同コース同距離別連対率','種牡馬同コース同距離別複勝率',\n",
    "    '種牡馬同周り勝率', '種牡馬同周り連対率', '種牡馬同周り複勝率',  '種牡馬同枠勝率', '種牡馬同枠連対率', '種牡馬同枠複勝率',\n",
    "    '父系統出走頭数','父系統全体勝率','父系統全体連対率','父系統全体複勝率','父系統競馬場別出走頭数','父系統競馬場別勝率','父系統競馬場別連対率','父系統競馬場別複勝率','父系統コース別出走頭数','父系統コース別勝率',\n",
    "    '父系統コース別連対率','父系統コース別複勝率','父系統距離別出走頭数','父系統距離別勝率','父系統距離別連対率','父系統距離別複勝率',\n",
    "    '父系統同コース同距離別出走頭数','父系統同コース同距離別勝率','父系統同コース同距離別連対率','父系統同コース同距離別複勝率',\n",
    "    '季節勝率', '季節連対率', '季節複勝率', '逃げ率','先行率','中団率','追込率','マクリ率','上がり3F平均',\n",
    "    '勝率','同競馬場勝率','同距離勝率','同競馬場同距離勝率','同騎手騎乗勝率','コースタイプ勝率','同距離同クラス勝率','同枠タイプ生涯勝率',\n",
    "    '連対率','同競馬場連対率','同距離連対率','同競馬場同距離連対率','同騎手騎乗連対率','コースタイプ連対率','同距離同クラス連対率','同枠タイプ生涯連対率',\n",
    "    '複勝率','同競馬場複勝率','同距離複勝率','同競馬場同距離複勝率','同騎手騎乗複勝率','コースタイプ複勝率','同距離同クラス複勝率','同枠タイプ生涯複勝率',\n",
    "    '生涯出遅れ率','騎乗騎手年間出遅れ率'\n",
    "]\n",
    "\n",
    "b = b.set_index('race_id')\n",
    "for t in targets:\n",
    "    b[t + '偏差'] = b.groupby(level=0)[t].transform(standard_scaler)\n",
    "    \n",
    "b.drop(targets, axis=1, inplace=True)\n",
    "b.drop(['horse_race_id'], axis=1, inplace=True)\n",
    "b.to_pickle('./pickle_new/shinba_base.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41776413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>id</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>age</th>\n",
       "      <th>course</th>\n",
       "      <th>distance</th>\n",
       "      <th>result</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>multiple</th>\n",
       "      <th>affiliation_id</th>\n",
       "      <th>...</th>\n",
       "      <th>生涯出遅れ率偏差値</th>\n",
       "      <th>騎乗騎手年間出遅れ率偏差値</th>\n",
       "      <th>逃げ率</th>\n",
       "      <th>先行率</th>\n",
       "      <th>中団率</th>\n",
       "      <th>追込率</th>\n",
       "      <th>マクリ率</th>\n",
       "      <th>上がり3F平均</th>\n",
       "      <th>獲得賞金合計</th>\n",
       "      <th>付加賞金合計</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007090806040101</td>\n",
       "      <td>200709080604010101</td>\n",
       "      <td>2005100316</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>6</td>\n",
       "      <td>629</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>59.383576</td>\n",
       "      <td>53.461260</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007090806040101</td>\n",
       "      <td>200709080604010105</td>\n",
       "      <td>2005100929</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>2</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>44.567559</td>\n",
       "      <td>47.118061</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007090806040101</td>\n",
       "      <td>200709080604010104</td>\n",
       "      <td>2005101474</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>44.567559</td>\n",
       "      <td>54.469572</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007090806040101</td>\n",
       "      <td>200709080604010102</td>\n",
       "      <td>2005101743</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>74.199592</td>\n",
       "      <td>45.614760</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007090806040101</td>\n",
       "      <td>200709080604010108</td>\n",
       "      <td>2005103238</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>5</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>44.567559</td>\n",
       "      <td>45.119770</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672511</th>\n",
       "      <td>2022080704020412</td>\n",
       "      <td>202208070402041213</td>\n",
       "      <td>2019105293</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>8</td>\n",
       "      <td>1014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41.630455</td>\n",
       "      <td>32.190246</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.9</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672512</th>\n",
       "      <td>2022080704020412</td>\n",
       "      <td>202208070402041208</td>\n",
       "      <td>2019105413</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>7</td>\n",
       "      <td>1164</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>47.633050</td>\n",
       "      <td>63.977211</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>860.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672513</th>\n",
       "      <td>2022080704020412</td>\n",
       "      <td>202208070402041203</td>\n",
       "      <td>2019105515</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "      <td>5386</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>77.638822</td>\n",
       "      <td>42.679489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672514</th>\n",
       "      <td>2022080704020412</td>\n",
       "      <td>202208070402041214</td>\n",
       "      <td>2019105859</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>2</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>65.637233</td>\n",
       "      <td>56.923576</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672515</th>\n",
       "      <td>2022080704020412</td>\n",
       "      <td>202208070402041216</td>\n",
       "      <td>2019110060</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>9</td>\n",
       "      <td>5212</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>41.630455</td>\n",
       "      <td>60.009541</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672516 rows × 356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 race_id                  id    horse_id  age  course  \\\n",
       "0       2007090806040101  200709080604010101  2005100316    2       2   \n",
       "1       2007090806040101  200709080604010105  2005100929    2       2   \n",
       "2       2007090806040101  200709080604010104  2005101474    2       2   \n",
       "3       2007090806040101  200709080604010102  2005101743    2       2   \n",
       "4       2007090806040101  200709080604010108  2005103238    2       2   \n",
       "...                  ...                 ...         ...  ...     ...   \n",
       "672511  2022080704020412  202208070402041213  2019105293    3       1   \n",
       "672512  2022080704020412  202208070402041208  2019105413    3       1   \n",
       "672513  2022080704020412  202208070402041203  2019105515    3       1   \n",
       "672514  2022080704020412  202208070402041214  2019105859    3       1   \n",
       "672515  2022080704020412  202208070402041216  2019110060    3       1   \n",
       "\n",
       "        distance  result  jockey_id  multiple  affiliation_id  ...  生涯出遅れ率偏差値  \\\n",
       "0           1200       6        629         1               1  ...  59.383576   \n",
       "1           1200       2        679         0               1  ...  44.567559   \n",
       "2           1200       1        836         0               1  ...  44.567559   \n",
       "3           1200       3        711         0               1  ...  74.199592   \n",
       "4           1200       5        699         0               1  ...  44.567559   \n",
       "...          ...     ...        ...       ...             ...  ...        ...   \n",
       "672511      1600       8       1014         0               1  ...  41.630455   \n",
       "672512      1600       7       1164         0               2  ...  47.633050   \n",
       "672513      1600       5       5386         0               2  ...  77.638822   \n",
       "672514      1600       2       1093         0               2  ...  65.637233   \n",
       "672515      1600       9       5212         0               2  ...  41.630455   \n",
       "\n",
       "        騎乗騎手年間出遅れ率偏差値     逃げ率     先行率     中団率     追込率  マクリ率  上がり3F平均  獲得賞金合計  \\\n",
       "0           53.461260  0.0000  0.9999  0.0000  0.0000   0.0     38.9   255.0   \n",
       "1           47.118061  0.0000  0.3333  0.3333  0.3333   0.0     37.0    50.0   \n",
       "2           54.469572  0.5000  0.5000  0.0000  0.0000   0.0     35.9   410.0   \n",
       "3           45.614760  0.0000  0.0000  0.9999  0.0000   0.0     36.9     0.0   \n",
       "4           45.119770  0.0000  0.0000  0.9999  0.0000   0.0     36.8     0.0   \n",
       "...               ...     ...     ...     ...     ...   ...      ...     ...   \n",
       "672511      32.190246  0.0000  0.9999  0.0000  0.0000   0.0     33.9   600.0   \n",
       "672512      63.977211  0.1667  0.5000  0.1667  0.1667   0.0     36.6   860.0   \n",
       "672513      42.679489  0.0000  0.0000  0.5000  0.5000   0.0     34.6   720.0   \n",
       "672514      56.923576  0.0000  0.3333  0.5000  0.1667   0.0     35.1  1730.0   \n",
       "672515      60.009541  0.0000  0.6000  0.4000  0.0000   0.0     35.1  1145.0   \n",
       "\n",
       "        付加賞金合計  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "672511     NaN  \n",
       "672512     NaN  \n",
       "672513     0.0  \n",
       "672514     3.8  \n",
       "672515     0.0  \n",
       "\n",
       "[672516 rows x 356 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = b_copy.drop(['逃げ率偏差値','先行率偏差値','中団率偏差値','追込率偏差値','マクリ率偏差値','上がり3F平均偏差値','獲得賞金合計偏差値','付加賞金合計偏差値'], axis=1)\n",
    "horse_results_detail = pd.read_csv('./csv_new2/base/horse_results_detail.csv')\n",
    "horse_results_detail = horse_results_detail.drop(['horse_id', 'age', 'course', 'distance', 'career', 'date', 'race_id'], axis=1)\n",
    "dd = dd.merge(horse_results_detail[['id', '逃げ率','先行率','中団率','追込率','マクリ率','上がり3F平均','獲得賞金合計','付加賞金合計']], how='left', on='id')\n",
    "dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc268bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 新規レース追加\n",
    "new_races = pd.read_csv('./csv_new2/20221127/horse_results.csv')\n",
    "\n",
    "jockey_rate = pd.read_csv('./csv_new2/20221127/jockey_rate.csv')\n",
    "jockey_rate.drop(['id', 'jockey_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "trainer_rate = pd.read_csv('./csv_new2/20221127/trainer_rate.csv')\n",
    "trainer_rate.drop(['id', 'trainer_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "stallion_rate = pd.read_csv('./csv_new2/20221127/stallion_rate.csv')\n",
    "stallion_rate.drop(['place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "df_conc = new_races.merge(jockey_rate, how='left', on='horse_race_id')\n",
    "df_conc = df_conc.merge(trainer_rate, how='left', on='horse_race_id')\n",
    "df_conc = df_conc.merge(stallion_rate, how='left', on=['race_id', 'stallion_id'])\n",
    "\n",
    "weather = pd.read_csv('./csv_new2/20221127/weathers.csv')\n",
    "df_conc = df_conc.merge(weather, how='left', on='race_id')\n",
    "df_conc['date'] = df_conc['date_y']\n",
    "df_conc.drop(['date_y', 'date_x', 'start_time'], axis=1, inplace=True)\n",
    "\n",
    "horse_results_detail = pd.read_csv('./csv_new2/20221127/race_detail.csv')\n",
    "horse_results_detail = horse_results_detail.drop(['horse_id', 'age', 'course', 'distance', 'career', 'date', 'race_id'], axis=1)\n",
    "df_conc['id'] = df_conc['horse_race_id']\n",
    "df_conc = df_conc.merge(horse_results_detail, how='left', on='id')\n",
    "\n",
    "d = df_conc.copy()\n",
    "horse_sire_rate = pd.read_csv('./csv_new2/20221127/horse_sire_rate.csv')\n",
    "horse_sire_rate.drop(['race_id', 'name', 'course', 'distance', 'date', 'place_id', 'start_time'], axis=1, inplace=True)\n",
    "d = d.merge(horse_sire_rate, how='left', on='id')\n",
    "\n",
    "seasons = pd.read_csv('./csv_new2/20221127/season_rate.csv')\n",
    "seasons.drop(['horse_id'], axis=1, inplace=True)\n",
    "d = d.merge(seasons, how='left', on='id')\n",
    "\n",
    "d['date'] = d['date_x']\n",
    "d.drop(['name', 'date_x', 'date_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0fe44c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/2259639867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    }
   ],
   "source": [
    "standard_scaler = lambda  x: (x - x.mean()) / x.std()\n",
    "\n",
    "targets = [\n",
    "    '騎手全体勝率','騎手全体連対率','騎手全体複勝率','騎手競馬場別騎乗回数','騎手競馬場別勝率','騎手競馬場別連対率','騎手競馬場別複勝率',\n",
    "    '騎手コース別騎乗回数','騎手コース別勝率','騎手コース別連対率','騎手コース別複勝率','騎手距離別騎乗回数','騎手距離別勝率','騎手距離別連対率',\n",
    "    '騎手距離別複勝率','騎手同コース同距離別騎乗回数','騎手同コース同距離別勝率','騎手同コース同距離別連対率','騎手同コース同距離別複勝率',\n",
    "    '調教師全体勝率','調教師全体連対率','調教師全体複勝率','調教師競馬場別騎乗回数','調教師競馬場別勝率','調教師競馬場別連対率',\n",
    "    '調教師競馬場別複勝率','調教師コース別騎乗回数','調教師コース別勝率','調教師コース別連対率','調教師コース別複勝率','調教師距離別騎乗回数',\n",
    "    '調教師距離別勝率','調教師距離別連対率','調教師距離別複勝率','調教師同コース同距離別騎乗回数','調教師同コース同距離別勝率',\n",
    "    '調教師年齢別年間勝率', '調教師年齢別年間連対率', '調教師年齢別年間複勝率','調教師年齢別勝率', '調教師年齢別連対率', '調教師年齢別複勝率',\n",
    "    '調教師同コース同距離別連対率','調教師同コース同距離別複勝率','種牡馬全体勝率','種牡馬全体連対率','種牡馬全体複勝率',\n",
    "    '種牡馬競馬場別出走頭数','種牡馬競馬場別勝率','種牡馬競馬場別連対率','種牡馬競馬場別複勝率','種牡馬コース別出走頭数','種牡馬コース別勝率',\n",
    "    '種牡馬コース別連対率','種牡馬コース別複勝率','種牡馬距離別出走頭数','種牡馬距離別勝率','種牡馬距離別連対率','種牡馬距離別複勝率',\n",
    "    '種牡馬同コース同距離別出走頭数','種牡馬同コース同距離別勝率','種牡馬同コース同距離別連対率','種牡馬同コース同距離別複勝率',\n",
    "    '種牡馬同周り勝率', '種牡馬同周り連対率', '種牡馬同周り複勝率',  '種牡馬同枠勝率', '種牡馬同枠連対率', '種牡馬同枠複勝率',\n",
    "    '父系統出走頭数','父系統全体勝率','父系統全体連対率','父系統全体複勝率','父系統競馬場別出走頭数','父系統競馬場別勝率','父系統競馬場別連対率','父系統競馬場別複勝率','父系統コース別出走頭数','父系統コース別勝率',\n",
    "    '父系統コース別連対率','父系統コース別複勝率','父系統距離別出走頭数','父系統距離別勝率','父系統距離別連対率','父系統距離別複勝率',\n",
    "    '父系統同コース同距離別出走頭数','父系統同コース同距離別勝率','父系統同コース同距離別連対率','父系統同コース同距離別複勝率',\n",
    "    '季節勝率', '季節連対率', '季節複勝率', '逃げ率','先行率','中団率','追込率','マクリ率','上がり3F平均',\n",
    "    '勝率','同競馬場勝率','同距離勝率','同競馬場同距離勝率','同騎手騎乗勝率','コースタイプ勝率','同距離同クラス勝率','同枠タイプ生涯勝率',\n",
    "    '連対率','同競馬場連対率','同距離連対率','同競馬場同距離連対率','同騎手騎乗連対率','コースタイプ連対率','同距離同クラス連対率','同枠タイプ生涯連対率',\n",
    "    '複勝率','同競馬場複勝率','同距離複勝率','同競馬場同距離複勝率','同騎手騎乗複勝率','コースタイプ複勝率','同距離同クラス複勝率','同枠タイプ生涯複勝率',\n",
    "    '生涯出遅れ率','騎乗騎手年間出遅れ率', '同周り勝率', '同周り連対率', '同周り複勝率'\n",
    "]\n",
    "\n",
    "d = d.set_index('race_id')\n",
    "for t in targets:\n",
    "    d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
    "\n",
    "dcp_all_rb = d.copy()\n",
    "ind = ['先行指数', 'ペース指数', '上がり指数', 'スピード指数']\n",
    "for i in range(1, 6):\n",
    "    for idx in ind:\n",
    "        dcp_all_rb[str(i) + '走前'+ idx + '偏差'] = dcp_all_rb.groupby(level=0)[str(i) + '走前'+ idx].transform(standard_scaler)\n",
    "        \n",
    "d_conc = dcp_all_rb.reset_index()\n",
    "d_copy = d_conc.copy()\n",
    "\n",
    "# d_copy.drop(['ペース指数', '先行指数', 'スピード指数', '上がり指数'], axis=1, inplace=True)\n",
    "d_copy.to_pickle('./pickle_new/new_race_20221127.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c98b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
      "/var/folders/dn/99p8d8fn6g75hkllgmntdmxc0000gn/T/ipykernel_31913/3581091827.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "standard_scaler = lambda  x: (x - x.mean()) / x.std()\n",
    "\n",
    "# 新規レース追加(新馬戦用)\n",
    "new_races = pd.read_csv('./csv_new2/20221127/race_detail_shinba.csv')\n",
    "\n",
    "jockey_rate = pd.read_csv('./csv_new2/20221127/jockey_rate.csv')\n",
    "jockey_rate.drop(['id', 'jockey_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "trainer_rate = pd.read_csv('./csv_new2/20221127/trainer_rate.csv')\n",
    "trainer_rate.drop(['id', 'trainer_id', 'place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "stallion_rate = pd.read_csv('./csv_new2/20221127/stallion_rate.csv')\n",
    "stallion_rate.drop(['place_id', 'course', 'distance', 'date'], axis=1, inplace=True)\n",
    "\n",
    "df_conc = new_races.merge(jockey_rate, how='left', on='horse_race_id')\n",
    "df_conc = df_conc.merge(trainer_rate, how='left', on='horse_race_id')\n",
    "df_conc = df_conc.merge(stallion_rate, how='left', on=['race_id', 'stallion_id'])\n",
    "\n",
    "df_conc.drop(['result_except'], axis=1, inplace=True)\n",
    "\n",
    "weather = pd.read_csv('./csv_new2/20221127/weathers.csv')\n",
    "df_conc = df_conc.merge(weather, how='left', on='race_id')\n",
    "df_conc['date'] = df_conc['date_y']\n",
    "df_conc['id'] = df_conc['horse_race_id']\n",
    "df_conc.drop(['horse_race_id','date_y', 'date_x', 'start_time'], axis=1, inplace=True)\n",
    "\n",
    "horse_results_detail = pd.read_csv('./csv_new2/20221127/race_detail.csv')\n",
    "horse_results_detail = horse_results_detail.drop(['horse_id', 'age', 'course', 'distance', 'career', 'date', 'race_id'], axis=1)\n",
    "df_conc = df_conc.merge(horse_results_detail, how='left', on='id')\n",
    "\n",
    "d = df_conc.copy()\n",
    "horse_sire_rate = pd.read_csv('./csv_new2/20221127/horse_sire_rate.csv')\n",
    "horse_sire_rate.drop(['race_id', 'name', 'course', 'distance', 'date', 'place_id', 'start_time'], axis=1, inplace=True)\n",
    "d = d.merge(horse_sire_rate, how='left', on='id')\n",
    "\n",
    "seasons = pd.read_csv('./csv_new2/20221127/season_rate.csv')\n",
    "seasons.drop(['horse_id'], axis=1, inplace=True)\n",
    "d = d.merge(seasons, how='left', on='id')\n",
    "\n",
    "d['date'] = d['date_x']\n",
    "d.drop(['name', 'sireline', 'date_x', 'date_y'], axis=1, inplace=True)\n",
    "\n",
    "targets = [\n",
    "    '騎手全体勝率','騎手全体連対率','騎手全体複勝率','騎手競馬場別騎乗回数','騎手競馬場別勝率','騎手競馬場別連対率','騎手競馬場別複勝率',\n",
    "    '騎手コース別騎乗回数','騎手コース別勝率','騎手コース別連対率','騎手コース別複勝率','騎手距離別騎乗回数','騎手距離別勝率','騎手距離別連対率',\n",
    "    '騎手距離別複勝率','騎手同コース同距離別騎乗回数','騎手同コース同距離別勝率','騎手同コース同距離別連対率','騎手同コース同距離別複勝率',\n",
    "    '調教師全体勝率','調教師全体連対率','調教師全体複勝率','調教師競馬場別騎乗回数','調教師競馬場別勝率','調教師競馬場別連対率',\n",
    "    '調教師競馬場別複勝率','調教師コース別騎乗回数','調教師コース別勝率','調教師コース別連対率','調教師コース別複勝率','調教師距離別騎乗回数',\n",
    "    '調教師距離別勝率','調教師距離別連対率','調教師距離別複勝率','調教師同コース同距離別騎乗回数','調教師同コース同距離別勝率',\n",
    "    '調教師年齢別年間勝率', '調教師年齢別年間連対率', '調教師年齢別年間複勝率','調教師年齢別勝率', '調教師年齢別連対率', '調教師年齢別複勝率',\n",
    "    '調教師同コース同距離別連対率','調教師同コース同距離別複勝率','種牡馬全体勝率','種牡馬全体連対率','種牡馬全体複勝率',\n",
    "    '種牡馬競馬場別出走頭数','種牡馬競馬場別勝率','種牡馬競馬場別連対率','種牡馬競馬場別複勝率','種牡馬コース別出走頭数','種牡馬コース別勝率',\n",
    "    '種牡馬コース別連対率','種牡馬コース別複勝率','種牡馬距離別出走頭数','種牡馬距離別勝率','種牡馬距離別連対率','種牡馬距離別複勝率',\n",
    "    '種牡馬同コース同距離別出走頭数','種牡馬同コース同距離別勝率','種牡馬同コース同距離別連対率','種牡馬同コース同距離別複勝率',\n",
    "    '種牡馬同周り勝率', '種牡馬同周り連対率', '種牡馬同周り複勝率',  '種牡馬同枠勝率', '種牡馬同枠連対率', '種牡馬同枠複勝率',\n",
    "    '父系統出走頭数','父系統全体勝率','父系統全体連対率','父系統全体複勝率','父系統競馬場別出走頭数','父系統競馬場別勝率','父系統競馬場別連対率','父系統競馬場別複勝率','父系統コース別出走頭数','父系統コース別勝率',\n",
    "    '父系統コース別連対率','父系統コース別複勝率','父系統距離別出走頭数','父系統距離別勝率','父系統距離別連対率','父系統距離別複勝率',\n",
    "    '父系統同コース同距離別出走頭数','父系統同コース同距離別勝率','父系統同コース同距離別連対率','父系統同コース同距離別複勝率',\n",
    "    '季節勝率', '季節連対率', '季節複勝率', '逃げ率','先行率','中団率','追込率','マクリ率','上がり3F平均',\n",
    "    '勝率','同競馬場勝率','同距離勝率','同競馬場同距離勝率','同騎手騎乗勝率','コースタイプ勝率','同距離同クラス勝率','同枠タイプ生涯勝率',\n",
    "    '連対率','同競馬場連対率','同距離連対率','同競馬場同距離連対率','同騎手騎乗連対率','コースタイプ連対率','同距離同クラス連対率','同枠タイプ生涯連対率',\n",
    "    '複勝率','同競馬場複勝率','同距離複勝率','同競馬場同距離複勝率','同騎手騎乗複勝率','コースタイプ複勝率','同距離同クラス複勝率','同枠タイプ生涯複勝率',\n",
    "    '生涯出遅れ率','騎乗騎手年間出遅れ率'\n",
    "]\n",
    "\n",
    "d = d.set_index('race_id')\n",
    "for t in targets:\n",
    "    d[t + '偏差'] = d.groupby(level=0)[t].transform(standard_scaler)\n",
    "    \n",
    "d.drop(targets, axis=1, inplace=True)\n",
    "\n",
    "d = d.reset_index()\n",
    "d.to_pickle('./pickle_new/new_race_20221127_shinba.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711d03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((set(d_copy.keys()) - set(b.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_env",
   "language": "python",
   "name": "vir_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
